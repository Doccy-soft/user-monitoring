<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Doccy</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-100 flex items-center justify-center min-h-screen">
    <!-- Login Page -->
    <div id="login-page" class="bg-white p-8 rounded-lg shadow-md w-96">
        <div class="text-center mb-6">
            <div class="w-16 h-16 bg-blue-500 rounded-full mx-auto flex items-center justify-center">
                <img src="doccy.gif" alt="Doccy Logo" class="w-29 h-29">
            </div>
            <h1 class="text-2xl font-bold mt-4">Doccy</h1>
            <p class="text-gray-600">Record and send audio to your desktop</p>
        </div>
        <div>
            <label for="username" class="block text-gray-700 mb-2">Username</label>
            <input type="text" id="username" class="w-full p-2 border rounded mb-4" placeholder="Enter your username">
            <button id="continue-btn" class="w-full text-white p-2 rounded" style="background-color: #132792;">Continue</button>
        </div>
    </div>

    <!-- Recording Page -->
    <div id="recording-page" class="hidden bg-white p-8 rounded-lg shadow-md w-96">
        <div class="flex justify-between mb-4">
            <span id="login-status" class="text-sm">Logged in as <span id="logged-username"></span></span>
            <button id="logout-btn" class="text-sm text-black">Logout ‚Üí</button>
        </div>
        <h2 class="text-xl font-bold mb-2">Audio Recorder</h2>
        <p class="text-gray-600 mb-4">Tap to begin recording</p>
        <canvas id="wave-canvas" class="w-full h-32 bg-gray-200 mb-4"></canvas>
        <button id="record-btn" class="w-full text-white p-2 rounded flex items-center justify-center" style="background-color: #132792;">
            <span class="mr-2">üéôÔ∏è</span> Record
        </button>
        <p class="text-sm text-gray-600 mt-4">Your recordings will be saved as <span id="filename"></span> on your desktop.</p>
        <p id="https-warning" class="text-sm text-red-600 mt-2 hidden">Recording is not supported on mobile devices without HTTPS. Please access this site over HTTPS or use a desktop browser.</p>
    </div>

<script>
    document.addEventListener('DOMContentLoaded', () => {
        const wsUrl = "wss://0igt7rsq5c.execute-api.us-east-1.amazonaws.com/production"; // Replace with your WebSocket URL
        const bucketName = "sound-capture-uploads"; // Replace with your bucket name
        const loginPage = document.getElementById('login-page');
        const recordingPage = document.getElementById('recording-page');
        const continueBtn = document.getElementById('continue-btn');
        const usernameInput = document.getElementById('username');
        const recordBtn = document.getElementById('record-btn');
        const waveCanvas = document.getElementById('wave-canvas');
        const filenameSpan = document.getElementById('filename');
        const logoutBtn = document.getElementById('logout-btn');
        const loggedUsername = document.getElementById('logged-username');
        const httpsWarning = document.getElementById('https-warning');
        let username;
        let ws;
        let audioContext;
        let analyser;
        let processor;
        let mediaRecorder;
        let chunks = [];
        let isRecording = false;
        let reconnectAttempts = 0;
        const baseReconnectDelay = 200; // Reduced to 200ms for faster reconnection
        let micStream = null;
        const silenceThreshold = 0.03; // RMS amplitude threshold for silence
        const silenceDuration = 500; // Silence duration to split segments (ms)
        let silenceStart = null;
        let nonSilentSamples = [];
        let sourceNode;
        let sampleBuffer = [];
        let bufferDuration = 0;

        // Check for HTTPS and mobile device
        const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
        if (location.protocol !== 'https:' && isMobile) {
            console.error('This page must be served over HTTPS to access the microphone on mobile devices.');
            httpsWarning.classList.remove('hidden');
            recordBtn.disabled = true; // Disable recording on mobile without HTTPS
        }

        // Check for saved username and initialize
        function initialize() {
            username = localStorage.getItem('username');
            if (username) {
                loginPage.classList.add('hidden');
                recordingPage.classList.remove('hidden');
                loggedUsername.textContent = username;
                filenameSpan.textContent = `${username}_date.wav`;
            }
        }

        // Handle login
        continueBtn.addEventListener('click', () => {
            username = usernameInput.value.trim();
            if (username) {
                localStorage.setItem('username', username);
                loginPage.classList.add('hidden');
                recordingPage.classList.remove('hidden');
                loggedUsername.textContent = username;
                filenameSpan.textContent = `${username}_date.wav`;
            } else {
                alert('Please enter a username.');
            }
        });

        // Handle logout
        logoutBtn.addEventListener('click', () => {
            if (ws) ws.close();
            localStorage.removeItem('username');
            localStorage.removeItem('micPermission');
            recordingPage.classList.add('hidden');
            loginPage.classList.remove('hidden');
            usernameInput.value = '';
            if (micStream) {
                micStream.getTracks().forEach(track => track.stop());
                micStream = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            isRecording = false;
            sampleBuffer = [];
            bufferDuration = 0;
            nonSilentSamples = [];
        });

        // Connect to WebSocket with reconnection logic
        function connectWebSocket() {
            const fullWsUrl = `${wsUrl}?username=${username}&deviceType=mobile`;
            ws = new WebSocket(fullWsUrl);
            ws.onopen = () => {
                console.log('Connected to', fullWsUrl);
                reconnectAttempts = 0; // Reset attempts on successful connection
            };
            ws.onerror = (error) => {
                console.error('WebSocket error:', error, fullWsUrl);
                console.error('This may be due to CORS issues. Ensure the WebSocket server allows connections from your static site domain.');
            };
            ws.onclose = () => {
                console.log('WebSocket closed');
                if (isRecording) { // Reconnect only if recording
                    const delay = baseReconnectDelay * Math.pow(1.5, reconnectAttempts); // Reduced backoff factor
                    console.log(`Attempting to reconnect in ${delay}ms...`);
                    setTimeout(() => {
                        reconnectAttempts++;
                        connectWebSocket();
                    }, delay);
                } else {
                    console.log('Recording stopped, no further reconnection attempts');
                }
            };
        }

        // Handle recording with ScriptProcessorNode
        recordBtn.addEventListener('click', async () => {
            // Initialize or resume AudioContext
            if (!audioContext) {
                audioContext = new AudioContext({ sampleRate: 16000 });
                console.log('AudioContext created');
            }
            if (audioContext.state === 'suspended') {
                try {
                    await audioContext.resume();
                    console.log('AudioContext resumed successfully');
                } catch (err) {
                    console.error('Failed to resume AudioContext:', err);
                    alert('Unable to start audio context. Please try again.');
                    return;
                }
            }
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            try {
                console.log('Attempting to get microphone access');
                if (!micStream) {
                    micStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            sampleSize: 16
                        }
                    });
                    console.log('Microphone stream created:', micStream);
                    localStorage.setItem('micPermission', 'granted');
                    // Monitor permission changes
                    navigator.permissions.query({ name: 'microphone' }).then(permissionStatus => {
                        permissionStatus.onchange = () => {
                            if (permissionStatus.state === 'granted') {
                                localStorage.setItem('micPermission', 'granted');
                            } else {
                                localStorage.removeItem('micPermission');
                                if (micStream) {
                                    micStream.getTracks().forEach(track => track.stop());
                                    micStream = null;
                                }
                            }
                        };
                    });
                }
                sourceNode = audioContext.createMediaStreamSource(micStream);
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                sourceNode.connect(processor);
                processor.connect(audioContext.destination);
                sourceNode.connect(analyser);
                console.log('Audio pipeline connected');

                // Reset buffer when starting recording
                sampleBuffer = [];
                bufferDuration = 0;

                processor.onaudioprocess = (e) => {
                    if (!isRecording) return; // Stop processing if not recording
                    const inputData = e.inputBuffer.getChannelData(0);
                    const samples = new Float32Array(inputData);
                    console.log('Processing audio data, sample length:', samples.length); // Debug

                    // Calculate RMS for silence detection
                    let sum = 0;
                    for (let i = 0; i < samples.length; i++) {
                        sum += samples[i] * samples[i];
                    }
                    const rms = Math.sqrt(sum / samples.length);
                    const isSilentChunk = rms < silenceThreshold;

                    // Duration of this buffer in milliseconds
                    const chunkDuration = (samples.length / audioContext.sampleRate) * 1000;

                    if (!isSilentChunk) {
                        sampleBuffer.push(...samples);
                        bufferDuration += chunkDuration;
                        silenceStart = null; // Reset silence timer
                    } else {
                        if (!silenceStart) {
                            silenceStart = Date.now();
                        } else {
                            const silenceTime = Date.now() - silenceStart;
                            if (sampleBuffer.length > 0) {
                                // Convert accumulated samples to WAV and upload
                                const audioBuffer = createAudioBuffer(sampleBuffer);
                                const wavBlob = audioBufferToWav(audioBuffer);
                                uploadToS3(wavBlob);
                                sampleBuffer = []; // Clear buffer
                                bufferDuration = 0;
                            }
                            if (silenceTime >= silenceDuration) {
                                silenceStart = null; // Reset after prolonged silence
                            }
                        }
                    }
                };
            } catch (err) {
                console.error('Error accessing microphone:', err);
                localStorage.removeItem('micPermission');
                if (micStream) {
                    micStream.getTracks().forEach(track => track.stop());
                    micStream = null;
                }
                alert('Failed to access microphone. Please ensure you have granted microphone permissions.');
                return;
            }
            if (!isRecording) {
                reconnectAttempts = 0; // Reset attempts on new recording session
                connectWebSocket(); // Connect WebSocket when recording starts
                isRecording = true;
                recordBtn.textContent = 'Stop';
                drawWave();
            } else {
                isRecording = false;
                recordBtn.textContent = 'Record';
                processor.disconnect();
                sourceNode.disconnect();
                if (micStream) {
                    micStream.getTracks().forEach(track => track.stop()); // Stop the microphone stream
                    micStream = null; // Reset stream
                }
                if (ws) {
                    ws.close(); // Disconnect WebSocket when stopping
                }
                if (sampleBuffer.length > 0) {
                    const audioBuffer = createAudioBuffer(sampleBuffer);
                    const wavBlob = audioBufferToWav(audioBuffer);
                    uploadToS3(wavBlob);
                    sampleBuffer = []; // Clear buffer
                    bufferDuration = 0;
                }
                // Remove the onaudioprocess event to prevent further processing
                if (processor) {
                    processor.onaudioprocess = null;
                }
            }
        });

        // Create AudioBuffer from raw samples
        function createAudioBuffer(samples) {
            const audioBuffer = audioContext.createBuffer(1, samples.length, audioContext.sampleRate);
            const channelData = audioBuffer.getChannelData(0);
            for (let i = 0; i < samples.length; i++) {
                channelData[i] = samples[i];
            }
            return audioBuffer;
        }

        // Convert AudioBuffer to WAV (mono, 16 kHz, 16-bit)
        function audioBufferToWav(buffer) {
            const numChannels = 1;
            const sampleRate = 16000;
            const format = 1;
            const bitDepth = 16;
            const bytesPerSample = bitDepth / 8;
            const blockAlign = numChannels * bytesPerSample;
            const dataSize = buffer.length * numChannels * bytesPerSample;
            const bufferArray = new ArrayBuffer(44 + dataSize);
            const view = new DataView(bufferArray);
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + dataSize, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, format, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * blockAlign, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitDepth, true);
            writeString(view, 36, 'data');
            view.setUint32(40, dataSize, true);
            let offset = 44;
            for (let i = 0; i < buffer.length; i++) {
                const sample = buffer.getChannelData(0)[i];
                const val = Math.max(-1, Math.min(1, sample)) * 32767;
                view.setInt16(offset, val, true);
                offset += 2;
            }
            return new Blob([bufferArray], { type: 'audio/wav' });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // Upload to S3 and send URI via WebSocket
        async function uploadToS3(wavBlob) {
            const timestamp = Date.now();
            const s3Key = `${username}/${username}_${timestamp}.wav`;
            console.log(`Uploading ${s3Key} to S3...`);
            // Fetch pre-signed URL
            const response = await fetch('https://3d6vpnxe79.execute-api.us-east-1.amazonaws.com/prod/generate-presigned-url', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ key: s3Key, bucket: bucketName })
            });
            if (!response.ok) {
                console.error('Failed to fetch pre-signed URL:', response.statusText);
                console.error('This may be due to CORS issues. Ensure the API allows requests from your static site domain.');
                return;
            }
            const { url } = await response.json();

            // Upload to S3
            const uploadResponse = await fetch(url, {
                method: 'PUT',
                body: wavBlob,
                headers: { 'Content-Type': 'audio/wav' }
            });
            if (!uploadResponse.ok) {
                console.error('Failed to upload to S3:', uploadResponse.statusText);
                return;
            }
            console.log(`Uploaded ${s3Key} to S3`);

            // Send S3 URI to desktop app via WebSocket
            const s3Uri = `s3://${bucketName}/${s3Key}`;
            const message = JSON.stringify({ action: 'sendS3Uri', s3Uri: s3Uri });
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(message);
            } else {
                console.error('WebSocket is not open');
            }
        }

        // Draw moving wave
        function drawWave() {
            if (!isRecording) return;
            const canvasCtx = waveCanvas.getContext('2d');
            const WIDTH = waveCanvas.width;
            const HEIGHT = waveCanvas.height;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteTimeDomainData(dataArray);
            console.log('Analyser data:', dataArray); // Debug
            canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = 'rgb(0, 0, 255)';
            canvasCtx.beginPath();
            const sliceWidth = WIDTH * 1.0 / bufferLength;
            let x = 0;
            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * HEIGHT / 2;
                if (i === 0) {
                    canvasCtx.moveTo(x, y);
                } else {
                    canvasCtx.lineTo(x, y);
                }
                x += sliceWidth;
            }
            canvasCtx.lineTo(WIDTH, HEIGHT / 2);
            canvasCtx.stroke();
            requestAnimationFrame(drawWave);
        }

        // Initialize on page load
        initialize();
    });
</script>
</body>
</html>